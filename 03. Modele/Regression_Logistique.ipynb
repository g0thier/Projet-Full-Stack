{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>réalisateur</th>\n",
       "      <th>producteur</th>\n",
       "      <th>postal</th>\n",
       "      <th>debut</th>\n",
       "      <th>fin</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>imdb_search</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>parental_advisor</th>\n",
       "      <th>duree</th>\n",
       "      <th>genre</th>\n",
       "      <th>imdb_note</th>\n",
       "      <th>metascore</th>\n",
       "      <th>vote</th>\n",
       "      <th>resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOUT S'EST BIEN PASSE</td>\n",
       "      <td>Francois OZON</td>\n",
       "      <td>MANDARIN PRODUCTION</td>\n",
       "      <td>75013</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>48.83566</td>\n",
       "      <td>2.348315</td>\n",
       "      <td>https://www.imdb.com/search/title/?title=TOUT+...</td>\n",
       "      <td>Everything Went Fine</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>6.8</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>When André, 85, has a stroke, Emmanuelle hurri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   titre    réalisateur           producteur  postal  \\\n",
       "0  TOUT S'EST BIEN PASSE  Francois OZON  MANDARIN PRODUCTION   75013   \n",
       "\n",
       "        debut         fin  latitude  longitude  \\\n",
       "0  2020-08-20  2020-08-21  48.83566   2.348315   \n",
       "\n",
       "                                         imdb_search                 title  \\\n",
       "0  https://www.imdb.com/search/title/?title=TOUT+...  Everything Went Fine   \n",
       "\n",
       "   date parental_advisor  duree              genre  imdb_note  metascore  \\\n",
       "0  2021     Tous publics  113.0  Drama                    6.8       67.0   \n",
       "\n",
       "     vote                                             resume  \n",
       "0  1572.0  When André, 85, has a stroke, Emmanuelle hurri...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('export/table_imdb_paris.csv', delimiter=',', on_bad_lines='skip')\n",
    "\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"debut\"] = pd.to_datetime( dataset[\"debut\"], format='%Y-%m-%d')\n",
    "dataset[\"fin\"] = pd.to_datetime( dataset[\"fin\"], format='%Y-%m-%d')\n",
    "dataset[\"postal\"] = dataset[\"postal\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns= ['titre', 'réalisateur', 'producteur', 'imdb_search', 'title', 'resume'])\n",
    "#dataset[\"genre\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(dataset.shape)\\n\\ndataset[\"genre\"] = [ str(x).replace(\\' \\', \\'\\') for x in dataset[\"genre\"][:] ] \\ndataset[\"genre\"] = [ x.split(\",\") for x in dataset[\"genre\"][:] ]\\n\\ndataset = dataset.explode(\\'genre\\').reset_index().drop(columns=[\\'index\\'])\\n\\n### REMAKE Categories\\n\\nlist = [\\'Family\\', \\'Animation\\']\\ndataset[\\'genre\\'] = dataset[\\'genre\\'].apply(lambda x: \\'Comedy\\' if x in list else x)\\n\\nlist = [\\'Biography\\',\\'War\\', \\'News\\', \\'Sport\\', \\'History\\']\\ndataset[\\'genre\\'] = dataset[\\'genre\\'].apply(lambda x: \\'Documentary\\' if x in list else x)\\n\\nlist = [\\'Crime\\', \\'Horror\\']\\ndataset[\\'genre\\'] = dataset[\\'genre\\'].apply(lambda x: \\'Thriller\\' if x in list else x)\\n\\nlist = [\\'Action\\', \\'Adventure\\']\\ndataset[\\'genre\\'] = dataset[\\'genre\\'].apply(lambda x: \\'Action/Adventure\\' if x in list else x)\\n\\nlist = [\\'Fantasy\\', \\'Sci-Fi\\', \\'Mystery\\']\\ndataset[\\'genre\\'] = dataset[\\'genre\\'].apply(lambda x: \\'Fiction\\' if x in list else x)\\n\\nlist = [\\'Music\\', \\'Reality-TV\\', \\'Musical\\', \\'Talk-Show\\',\\'Short\\']\\ndataset[\\'genre\\'] = dataset[\\'genre\\'].apply(lambda x: \\'Live\\' if x in list else x)\\n\\ndataset = dataset[dataset[\"genre\"] != \\'nan\\']\\n\\nprint(dataset.shape)\\n\\nprint(dataset[\"genre\"].value_counts())\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without this Block \n",
    "# Accuracy on training set :  0.5688698284561049\n",
    "# Accuracy on test set :  0.5614285714285714\n",
    "\n",
    "# With this Block\n",
    "#Accuracy on training set :  0.43447014242780607\n",
    "#Accuracy on test set :  0.40340488527017027\n",
    "'''\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset[\"genre\"] = [ str(x).replace(' ', '') for x in dataset[\"genre\"][:] ] \n",
    "dataset[\"genre\"] = [ x.split(\",\") for x in dataset[\"genre\"][:] ]\n",
    "\n",
    "dataset = dataset.explode('genre').reset_index().drop(columns=['index'])\n",
    "\n",
    "### REMAKE Categories\n",
    "\n",
    "list = ['Family', 'Animation']\n",
    "dataset['genre'] = dataset['genre'].apply(lambda x: 'Comedy' if x in list else x)\n",
    "\n",
    "list = ['Biography','War', 'News', 'Sport', 'History']\n",
    "dataset['genre'] = dataset['genre'].apply(lambda x: 'Documentary' if x in list else x)\n",
    "\n",
    "list = ['Crime', 'Horror']\n",
    "dataset['genre'] = dataset['genre'].apply(lambda x: 'Thriller' if x in list else x)\n",
    "\n",
    "list = ['Action', 'Adventure']\n",
    "dataset['genre'] = dataset['genre'].apply(lambda x: 'Action/Adventure' if x in list else x)\n",
    "\n",
    "list = ['Fantasy', 'Sci-Fi', 'Mystery']\n",
    "dataset['genre'] = dataset['genre'].apply(lambda x: 'Fiction' if x in list else x)\n",
    "\n",
    "list = ['Music', 'Reality-TV', 'Musical', 'Talk-Show','Short']\n",
    "dataset['genre'] = dataset['genre'].apply(lambda x: 'Live' if x in list else x)\n",
    "\n",
    "dataset = dataset[dataset[\"genre\"] != 'nan']\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "print(dataset[\"genre\"].value_counts())\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4720, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e0d45ad91eba>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[\"frequency\"][index] = frequency.values[genre]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4720, 12)\n",
      "Index(['postal', 'debut', 'fin', 'latitude', 'longitude', 'date',\n",
      "       'parental_advisor', 'duree', 'genre', 'imdb_note', 'metascore', 'vote'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Without this Block \n",
    "# Accuracy on training set :  0.5688698284561049\n",
    "# Accuracy on test set :  0.5614285714285714\n",
    "\n",
    "# With this Block\n",
    "# Accuracy on training set :  0.622382851445663\n",
    "# Accuracy on test set :  0.6045197740112994\n",
    "\n",
    "# Erase Second and Third Genre.\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "dataset[\"genre\"] = [ str(x).replace(' ', '') for x in dataset[\"genre\"][:] ] \n",
    "dataset[\"genre\"] = [ x.split(\",\") for x in dataset[\"genre\"][:] ]\n",
    "\n",
    "dataset = dataset.explode('genre').reset_index()\n",
    "\n",
    "frequency = dataset[\"genre\"].value_counts()\n",
    "\n",
    "frequency.index[0]\n",
    "frequency.values[0]\n",
    "\n",
    "dataset[\"frequency\"] = ''\n",
    "\n",
    "for index in range(len(dataset)):\n",
    "    for genre in range(len(frequency)):\n",
    "        if dataset[\"genre\"][index] == frequency.index[genre]:\n",
    "            dataset[\"frequency\"][index] = frequency.values[genre]\n",
    "\n",
    "dataset.sort_values(by='frequency', ascending=False)\n",
    "\n",
    "dataset = dataset.drop_duplicates(subset='index', keep=\"first\")\n",
    "\n",
    "dataset = dataset.drop(columns= ['index','frequency'])\n",
    "print(dataset.shape)\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.dtypes\n",
    "dataset = dataset.reindex(columns = [col for col in dataset.columns if col != 'genre'] + ['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postal               0.000000\n",
       "debut                0.000000\n",
       "fin                  0.000000\n",
       "latitude             0.000000\n",
       "longitude            0.000000\n",
       "date                 0.000000\n",
       "parental_advisor    28.389831\n",
       "duree               11.207627\n",
       "imdb_note           17.394068\n",
       "metascore           78.516949\n",
       "vote                17.394068\n",
       "genre                0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pourcentage_valeur_manquante = 100*dataset.isnull().sum()/dataset.shape[0]\n",
    "\n",
    "pourcentage_valeur_manquante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation Varibles / Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'genre'\n",
    "\n",
    "dataset = dataset.dropna(subset=[target_name]).reset_index()\n",
    "\n",
    "## Separation valeurs explicative et valeur cible\n",
    "Y = dataset[:][target_name]\n",
    "X = dataset.drop(columns= [target_name])\n",
    "\n",
    "## Separation en train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=0)\n",
    "# stratify = Y # option pour même ratio de réponse que sur la table Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                0.000000\n",
       "postal               0.000000\n",
       "debut                0.000000\n",
       "fin                  0.000000\n",
       "latitude             0.000000\n",
       "longitude            0.000000\n",
       "date                 0.000000\n",
       "parental_advisor    28.389831\n",
       "duree               11.207627\n",
       "imdb_note           17.394068\n",
       "metascore           78.516949\n",
       "vote                17.394068\n",
       "genre                0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pourcentage_valeur_manquante = 100*dataset.isnull().sum()/dataset.shape[0]\n",
    "\n",
    "pourcentage_valeur_manquante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Préprocessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Médiane quantitative & plus fréquent qualitatif\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import( OneHotEncoder, StandardScaler, LabelEncoder )\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create pipeline for numeric features\n",
    "numeric_features = X.select_dtypes([np.number]).columns # Automatically detect positions of numeric columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_features = X.select_dtypes(\"object\").columns # Automatically detect positions of categorical columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train) # Preprocessing influenceur\n",
    "X_test = preprocessor.transform(X_test) # Preprocessing copieur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage valeur cible qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder() # Label encoding\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_test = encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000) # Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train) # Training is always done on train set !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model.predict(X_train) # Predictions on training set\n",
    "Y_test_pred = model.predict(X_test) # Prédictions on test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "__Qualitatif (Classification)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.622382851445663\n",
      "Accuracy on test set :  0.6045197740112994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy on training set : \", accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"Accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classement valeurs explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-22-6fbb1cf91457>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [22]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print('Feature: %0d, Score: %.5f' % (i,v))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "feature_importance = f_regression(X_train, Y_train)\n",
    "\n",
    "# Create DataFrame with feature importance\n",
    "feature_ranking = pd.DataFrame(columns=dataset.columns[:-1], data=feature_importance, index=[\"f-score\", \"p-value\"])\n",
    "# Reshape DataFrame and sort by f-score\n",
    "feature_ranking = feature_ranking.transpose().sort_values([\"f-score\", \"p-value\"], ascending=False)\n",
    "# Create column with feature names\n",
    "feature_ranking = feature_ranking.reset_index().rename(columns = {'index': 'feature'})\n",
    "\n",
    "px.bar(feature_ranking.sort_values([\"f-score\", \"p-value\"]), x = 'f-score', y = 'feature')\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "importance = model.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
