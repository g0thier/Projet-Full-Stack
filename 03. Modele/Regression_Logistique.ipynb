{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>réalisateur</th>\n",
       "      <th>producteur</th>\n",
       "      <th>postal</th>\n",
       "      <th>debut</th>\n",
       "      <th>fin</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>imdb_search</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>parental_advisor</th>\n",
       "      <th>duree</th>\n",
       "      <th>genre</th>\n",
       "      <th>imdb_note</th>\n",
       "      <th>metascore</th>\n",
       "      <th>vote</th>\n",
       "      <th>resume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOUT S'EST BIEN PASSE</td>\n",
       "      <td>Francois OZON</td>\n",
       "      <td>MANDARIN PRODUCTION</td>\n",
       "      <td>75013</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>48.83566</td>\n",
       "      <td>2.348315</td>\n",
       "      <td>https://www.imdb.com/search/title/?title=TOUT+...</td>\n",
       "      <td>Everything Went Fine</td>\n",
       "      <td>2021</td>\n",
       "      <td>Tous publics</td>\n",
       "      <td>113.0</td>\n",
       "      <td>Drama</td>\n",
       "      <td>6.8</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>When André, 85, has a stroke, Emmanuelle hurri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   titre    réalisateur           producteur  postal  \\\n",
       "0  TOUT S'EST BIEN PASSE  Francois OZON  MANDARIN PRODUCTION   75013   \n",
       "\n",
       "        debut         fin  latitude  longitude  \\\n",
       "0  2020-08-20  2020-08-21  48.83566   2.348315   \n",
       "\n",
       "                                         imdb_search                 title  \\\n",
       "0  https://www.imdb.com/search/title/?title=TOUT+...  Everything Went Fine   \n",
       "\n",
       "   date parental_advisor  duree              genre  imdb_note  metascore  \\\n",
       "0  2021     Tous publics  113.0  Drama                    6.8       67.0   \n",
       "\n",
       "     vote                                             resume  \n",
       "0  1572.0  When André, 85, has a stroke, Emmanuelle hurri...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('export/table_imdb_paris.csv', delimiter=',', on_bad_lines='skip')\n",
    "\n",
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"debut\"] = pd.to_datetime( dataset[\"debut\"], format='%Y-%m-%d')\n",
    "dataset[\"fin\"] = pd.to_datetime( dataset[\"fin\"], format='%Y-%m-%d')\n",
    "dataset[\"postal\"] = dataset[\"postal\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns= ['titre', 'réalisateur', 'producteur', 'imdb_search', 'title', 'resume'])\n",
    "\n",
    "# dataset.dtypes\n",
    "dataset = dataset.reindex(columns = [col for col in dataset.columns if col != 'genre'] + ['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postal               0.000000\n",
       "debut                0.000000\n",
       "fin                  0.000000\n",
       "latitude             0.000000\n",
       "longitude            0.000000\n",
       "date                 0.000000\n",
       "parental_advisor    28.389831\n",
       "duree               11.207627\n",
       "imdb_note           17.394068\n",
       "metascore           78.516949\n",
       "vote                17.394068\n",
       "genre                1.186441\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pourcentage_valeur_manquante = 100*dataset.isnull().sum()/dataset.shape[0]\n",
    "\n",
    "pourcentage_valeur_manquante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation Varibles / Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'genre'\n",
    "\n",
    "dataset = dataset.dropna(subset=[target_name]).reset_index()\n",
    "\n",
    "## Separation valeurs explicative et valeur cible\n",
    "Y = dataset[:][target_name]\n",
    "X = dataset.drop(columns= [target_name])\n",
    "\n",
    "## Separation en train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=0)\n",
    "# stratify = Y # option pour même ratio de réponse que sur la table Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                0.000000\n",
       "postal               0.000000\n",
       "debut                0.000000\n",
       "fin                  0.000000\n",
       "latitude             0.000000\n",
       "longitude            0.000000\n",
       "date                 0.000000\n",
       "parental_advisor    27.530017\n",
       "duree               10.398799\n",
       "imdb_note           16.402230\n",
       "metascore           78.259005\n",
       "vote                16.402230\n",
       "genre                0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pourcentage_valeur_manquante = 100*dataset.isnull().sum()/dataset.shape[0]\n",
    "\n",
    "pourcentage_valeur_manquante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Préprocessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Médiane quantitative & plus fréquent qualitatif\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import( OneHotEncoder, StandardScaler, LabelEncoder )\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create pipeline for numeric features\n",
    "numeric_features = X.select_dtypes([np.number]).columns # Automatically detect positions of numeric columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_features = X.select_dtypes(\"object\").columns # Automatically detect positions of categorical columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train) # Preprocessing influenceur\n",
    "X_test = preprocessor.transform(X_test) # Preprocessing copieur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage valeur cible qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder() # Label encoding\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "Y_test = encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000) # Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train) # Training is always done on train set !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model.predict(X_train) # Predictions on training set\n",
    "Y_test_pred = model.predict(X_test) # Prédictions on test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "__Qualitatif (Classification)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set :  0.5688698284561049\n",
      "Accuracy on test set :  0.5614285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy on training set : \", accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"Accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classement valeurs explicatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-81-6fbb1cf91457>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [81]\u001b[0;36m\u001b[0m\n\u001b[0;31m    print('Feature: %0d, Score: %.5f' % (i,v))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "feature_importance = f_regression(X_train, Y_train)\n",
    "\n",
    "# Create DataFrame with feature importance\n",
    "feature_ranking = pd.DataFrame(columns=dataset.columns[:-1], data=feature_importance, index=[\"f-score\", \"p-value\"])\n",
    "# Reshape DataFrame and sort by f-score\n",
    "feature_ranking = feature_ranking.transpose().sort_values([\"f-score\", \"p-value\"], ascending=False)\n",
    "# Create column with feature names\n",
    "feature_ranking = feature_ranking.reset_index().rename(columns = {'index': 'feature'})\n",
    "\n",
    "px.bar(feature_ranking.sort_values([\"f-score\", \"p-value\"]), x = 'f-score', y = 'feature')\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "importance = model.coef_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
