{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import ( accuracy_score, f1_score, r2_score, mean_squared_error )\n",
    "from sklearn.model_selection import ( GridSearchCV, train_test_split )\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import( OneHotEncoder, StandardScaler, LabelEncoder )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'src/dataset.csv', delimiter=',', on_bad_lines='skip')\n",
    "\n",
    "corr_matrix = round(dataset.corr(), 4)\n",
    "\n",
    "fig = ff.create_annotated_heatmap(corr_matrix.values,\n",
    "                                  x = corr_matrix.columns.values.tolist(),\n",
    "                                  y = corr_matrix.index.values.tolist(),\n",
    "                                  )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numVotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "\n",
    "dfnumVotes = dataset.sort_values(by=['numVotes'])\n",
    "\n",
    "dfnumVotes = dfnumVotes[dfnumVotes['numVotes'] < 20000]\n",
    "dfnumVotes = dfnumVotes[dfnumVotes['numVotes'] > 200]\n",
    "\n",
    "print(len(dfnumVotes))\n",
    "\n",
    "px.histogram(dfnumVotes[\"numVotes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# duree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfduree = dfnumVotes.sort_values(by=['duree'])\n",
    "dfduree = dfduree[dfduree['duree'] < 150]\n",
    "dfduree = dfduree[dfduree['duree'] > 40]\n",
    "\n",
    "print(len(dfduree))\n",
    "\n",
    "px.histogram(dfduree[\"duree\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfyear = dfduree.sort_values(by=['year'])\n",
    "dfyear = dfyear[dfyear['year'] < 2017]\n",
    "dfyear = dfyear[dfyear['year'] > 1930]\n",
    "\n",
    "print(len(dfyear))\n",
    "\n",
    "px.histogram(dfyear[\"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgenre = dfyear\n",
    "countGenre = dfgenre['genre'].value_counts()\n",
    "countGenre = countGenre[countGenre[:] > 400 ] # Drop Less than 5% of biggest genre.\n",
    "listGenre = countGenre.keys().tolist()\n",
    "\n",
    "dfgenre = dfgenre[dfgenre['genre'].isin(listGenre)]\n",
    "\n",
    "print(len(dfgenre))\n",
    "\n",
    "countGenre.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parentalAdvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfparentalAdvisor = dfgenre\n",
    "countAdvisor = dfparentalAdvisor['parentalAdvisor'].value_counts()\n",
    "\n",
    "countAdvisor = countAdvisor[countAdvisor[:] > 1000 ] # Drop Less than 5% of biggest genre.\n",
    "print(countAdvisor)\n",
    "listGenre = countAdvisor.keys().tolist()\n",
    "\n",
    "dfparentalAdvisor = dfparentalAdvisor[dfparentalAdvisor['parentalAdvisor'].isin(listGenre)]\n",
    "\n",
    "print(len(dfparentalAdvisor))\n",
    "\n",
    "countAdvisor.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imdbRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfimdbRating = dfparentalAdvisor.sort_values(by=['imdbRating'])\n",
    "\n",
    "print(len(dfimdbRating))\n",
    "\n",
    "px.histogram(dfimdbRating[\"imdbRating\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetWithoutOutlier = dfimdbRating.drop(columns=['tconst', 'numVotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'imdbRating'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph de correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "corr_matrix = round(datasetWithoutOutlier.corr(), 4)\n",
    "\n",
    "fig = ff.create_annotated_heatmap(corr_matrix.values,\n",
    "                                  x = corr_matrix.columns.values.tolist(),\n",
    "                                  y = corr_matrix.index.values.tolist(),\n",
    "                                  )\n",
    "\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separation Varibles / Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separation valeurs explicative et valeur cible\n",
    "Y = datasetWithoutOutlier[:][target_name]\n",
    "X = datasetWithoutOutlier.drop(columns= [target_name])\n",
    "\n",
    "## Separation en train/test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=0, stratify=Y)\n",
    "# stratify = Y # option pour même ratio de réponse que sur la table Y.\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Préprocessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Médiane quantitative & plus fréquent qualitatif\n",
    "\n",
    "\n",
    "\n",
    "# Create pipeline for numeric features\n",
    "numeric_features = X.select_dtypes([np.number]).columns # Automatically detect positions of numeric columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # missing values will be replaced by columns' median\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create pipeline for categorical features\n",
    "categorical_features = X.select_dtypes(\"object\").columns # Automatically detect positions of categorical columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # missing values will be replaced by most frequent value\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])\n",
    "\n",
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train) # Preprocessing influenceur\n",
    "X_test = preprocessor.transform(X_test) # Preprocessing copieur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_jobs=-1, verbose=2) \n",
    "# n_jobs=-1 -> Utilisation de tout les cores \n",
    "# verbose=2 -> Affiche toutes les info de constructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "### Random Forest model : Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grid of values to be tested\n",
    "\n",
    "params = {\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'n_estimators': [10, 20, 40, 60, 80, 100]\n",
    "}\n",
    "'''\n",
    "params = {\n",
    "    'max_depth': [4, 6, 8, 10, 12, 14],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf': [1, 2, 5, 7, 10],\n",
    "    'min_samples_split': [2, 4, 8, 16, 32, 64],\n",
    "    'n_estimators': [10, 20, 40, 60, 80, 100, 200]\n",
    "}\n",
    "'''\n",
    "gridsearch = GridSearchCV(model, param_grid = params, cv = 3) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "# 36m 6.5s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = gridsearch.predict(X_train) # Predictions on training set\n",
    "Y_test_pred = gridsearch.predict(X_test) # Prédictions on test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search : Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean squared error\n",
    "mse = mean_squared_error(Y_test, Y_test_pred)\n",
    "print(\"Mean squared error : \", mse)\n",
    "print(\"Mean error : \", mse**0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(x = Y_test, y = Y_test_pred, opacity=0.2, width=650, height=600, marginal_y='violin')\n",
    "fig.update_layout( margin=dict(l=20, r=10, t=10, b=10) )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# joblib.dump(gridsearch.best_estimator_, \"export/random_forest.joblib\", compress=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
